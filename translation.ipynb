{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dowloading and Saving Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"facebook/nllb-200-distilled-1.3B\"\n",
    "save_directory = \"./nllb-200-distilled-1.3B\"\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Save the tokenizer and model locally\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {save_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation Frame Work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "save_directory = \"./nllb-200-distilled-1.3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(save_directory).to(device)\n",
    "\n",
    "def translate(text, src_lang, tgt_lang):\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    translated_tokens = model.generate(**inputs,forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text = \"There's a hot new club in town that everyone is itching to gain entrance into.\"\n",
    "src_lang = \"eng_Latn\" \n",
    "tgt_lang = \"tel_Telu\"\n",
    "\n",
    "translated_text = translate(src_text, src_lang, tgt_lang)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For longer texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Check if MPS is available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the path to the model\n",
    "model_id = \"facebook/nllb-200-distilled-1.3B\"\n",
    "local_model_path = model_id\n",
    "\n",
    "# Load the tokenizer and model from the local directory\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(local_model_path).to(device)\n",
    "\n",
    "def translate_text(text, src_lang, tgt_lang, max_length=512):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding=\"longest\").to(device)\n",
    "    translated_tokens = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang],\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def chunk_text(text, max_tokens=512):\n",
    "    tokens = tokenizer.encode(text, return_tensors=\"pt\")[0]\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk = tokens[i:i + max_tokens]\n",
    "        chunks.append(tokenizer.decode(chunk))\n",
    "    return chunks\n",
    "\n",
    "def iterative_translation(text, src_lang, tgt_lang, target_word_count=100):\n",
    "    while True:\n",
    "        chunks = chunk_text(text)\n",
    "        translations = [translate_text(chunk, src_lang, tgt_lang) for chunk in chunks]\n",
    "        combined_translation = \" \".join(translations)\n",
    "        \n",
    "        word_count = len(combined_translation.split())\n",
    "        if word_count <= target_word_count:\n",
    "            return combined_translation\n",
    "        \n",
    "        text = combined_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language usage - https://github.com/facebookresearch/flores/tree/main/flores200#languages-in-flores-200\n",
    "src_text = \"\"\"There's a hot new club in town that everyone is itching to gain entrance into. \n",
    "The entry is free, and there are no membership fees or exclusive conditions. \n",
    "Literally all you have to do, is wake up and show up. The majority of us already know the importance of starting our day right, \n",
    "but getting up at 5 am might sound a little too \"alarming.\" However, if you want to maximize your productivity, \n",
    "and show up with the right energy and mindset for what matters, then you might want to join the 5 am Club. \n",
    "The 5 am Club, is a self-help parable that shows us how to embrace a revolutionary morning routine, that delivers results. \n",
    "World-famous productivity and leadership expert, Robin Sharma teaches us how to use the first \n",
    "hour of our day to harness our creative capacity, protect our sanity, and drive personal growth. \n",
    "Author Robin Sharma believes that when we rise at 5 am, when the world is quiet and devoid of energy-sapping distractions, \n",
    "this is when we learn to master ourselves. \"\"\"\n",
    "src_lang = \"eng_Latn\"\n",
    "tgt_lang = \"tel_Telu\"\n",
    "\n",
    "translated_text = iterative_translation(src_text, src_lang, tgt_lang)\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "print(\"Model has been removed from the device and memory is freed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainews",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
